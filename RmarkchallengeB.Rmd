---
title: "Challenge B in R Programming"
author: "D. Goninet & D. Lachiver"
date: "25 novembre 2017"
output: pdf_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages, include = FALSE}
load.libraries <- c('tidyverse', 'readr', 'class', 'np')
install.lib <- load.libraries[!load.libraries %in% installed.packages()]
for(libs in install.lib) install.packages(libs, dependencies = TRUE)
sapply(load.libraries, require, character = TRUE)
```

Our Github repository for this challenge : 
https://github.com/doriangoninet/RProgChallengeB.

# Task 1B

```{r 1B.setup, include = FALSE}
# importing data
train <- read_csv("train.csv")
test <- read.csv("test.csv")
```

## Step 1

We chose a Kernel Regression With Mixed Data Types. This is a Non-Parametric Kernel Estimation. We chose it for its simplicity and its adaptability - it takes a mix of continuous, ordered and unordered factor variables.  This is a method which, with observations, build kernel estimators and recognize each type of used variables to classify those into these kernel estimators.  But, the inconvenient of this method is that the execution time for most routines is, exponentially increasing in the number of observations and increases with the number of variables involved.

## Step 2

Like it's explained above, we have to convert our character variables - which are not recognized by our ML thecnique - in factor variables.

```{r 1B.step2.setup convert char to fact, results = FALSE, echo = (3)}
## Converting character to factors 
sapply(train, class)
train[sapply(train, is.character)] <- lapply(train[sapply(train, is.character)], as.factor)
sapply(train, class)
```

Next, we clean up all variables with more than 100 missing observations, and afetr that, we clean up all observations with any missing data.

```{r 1B.step2.setup missing data, include = FALSE}

# removing variables with missing obs. above 100
remove.vars <- train %>% summarise_all(.funs = funs(sum(is.na(.)))) %>% gather(key = "feature", value = "missing.observations") %>% filter(missing.observations > 100) %>% select(feature) %>% unlist

train <- train %>% select(- one_of(remove.vars))

# removing observations with any NA
train %>% summarise_all(.funs = funs(sum(is.na(.)))) %>% gather(key = "feature", value = "missing.observations") %>% filter(missing.observations > 0)

train <- train %>% filter(is.na(GarageType) == FALSE, is.na(MasVnrType) == FALSE, is.na(BsmtFinType2) == FALSE, is.na(BsmtExposure) == FALSE, is.na(Electrical) == FALSE)

train %>% summarise_all(.funs = funs(sum(is.na(.)))) %>% gather(key = "feature", value = "missing.observations") %>% filter(missing.observations > 0)
```

Once this is done, we can run the `ML technique`.

```{r 1B.step2, include = TRUE, results = FALSE}
bw <- npregbw(SalePrice ~ MSZoning + LotArea + Neighborhood  + YearBuilt + OverallQual, data = train, bws=c(0.732623, 4366.52, 0.5143274, 2.216515, 0.4687656),bandwidth.compute = FALSE)
model_np <- npreg(bw, newdata = test, residuals = TRUE)
```

We used a little trick to make this code more faster to compute: usually, `bandwidth` need to be compute through variables choosen. But, it takes about 10 minutes. So after a single computation, we have included the values of the bandwidth in the model. We used the same variables as in the previous challenge for more speed and consistency.  
However, a hidden piece of code is below for verifications, if needed.

```{r 1B.step2.verif, eval = FALSE, include = FALSE}
bw <- npregbw(SalePrice ~ MSZoning + LotArea + Neighborhood  + YearBuilt + OverallQual, data = train, bandwidth.compute = TRUE)
```


## Step 3

```{r predictions from Challenge A, include = FALSE}
model_lm <- lm(SalePrice ~ MSZoning + LotArea + Neighborhood  + YearBuilt + OverallQual, data = train)

predlm <- predict(model_lm, newdata = test)
predlm <- na.omit(predlm)
```

```{r predictions from Challenge B, include = FALSE}
prednp <- predict(model_np, newdata = test)
```

```{r marge dataset, include = FALSE}
merge <- matrix(data = (predlm - prednp))
absmerge <- abs(merge)
mean1 <- mean(absmerge)

relativemerge <- matrix(data = (predlm - prednp) / prednp)
absrelativemerge <- abs(relativemerge)
mean2 <- mean(absrelativemerge)


relativemerge2 <- matrix(data = (prednp - predlm) / predlm)
absrelativemerge2 <- abs(relativemerge2)
(absrelativemerge2)
```

We generated predictions for both models, computed their difference line by line, and made a mean of their absolute values, which is `r toString(round((mean1), 0))` $. This corresponds to a difference of about `r toString(round((mean2*100), 2))` % between these two models.


# Task 3B

## Step 1

```{r 3B.setup, eval=FALSE, include=TRUE}
CNIL <- read.csv("OpenCNIL.csv", sep = ";", encoding = "Winlatin1")
head(CNIL)
```